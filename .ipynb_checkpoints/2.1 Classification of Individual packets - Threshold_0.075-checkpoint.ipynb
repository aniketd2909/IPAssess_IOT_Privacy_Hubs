{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "129dc573",
   "metadata": {},
   "source": [
    "## This file makes machine learning application for individual packets for Aalto University. \n",
    "### Used machine learning algorithms: RF (Random Forest) DT (Decision Trees)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ddef76",
   "metadata": {},
   "source": [
    "###  importing relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15f83c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from numpy import array\n",
    "from random import random\n",
    "from sklearn import metrics\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB#57\n",
    "from sklearn.naive_bayes import GaussianNB#52\n",
    "from sklearn.naive_bayes import MultinomialNB#56\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import csv\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21b1bd0",
   "metadata": {},
   "source": [
    "### Discovering dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37036bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./dataset/IPAssess_hub.csv',\n",
       " './dataset/Threshold_0.05.csv',\n",
       " './dataset/Threshold_0.06.csv',\n",
       " './dataset/Threshold_0.06_Accuracy.csv',\n",
       " './dataset/Main_hub.csv',\n",
       " './dataset/Threshold_0.075.csv',\n",
       " './dataset/Threshold_0.05_Accuracy.csv',\n",
       " './dataset/Main_hub_reduced.csv',\n",
       " './dataset/Main_Hub_Accuracy.csv',\n",
       " './dataset/IPAssess_Hub_Accuracy.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_the_way(path,file_format):\n",
    "    files_add = []\n",
    "    # r=root, d=directories, f = files\n",
    "    for r, d, f in os.walk(path):\n",
    "        for file in f:\n",
    "            if file_format in file:\n",
    "                files_add.append(os.path.join(r, file))  \n",
    "    return files_add\n",
    "files_add=find_the_way('./dataset/','.csv')\n",
    "files_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b43fd52",
   "metadata": {},
   "source": [
    "### Discovering Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ad4bf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def target_names():\n",
    "    name=files_add[5]\n",
    "    df = pd.read_csv(name)\n",
    "    target_names=sorted(list(df[df.columns[-2]].unique()))\n",
    "    return target_names\n",
    "target_names=target_names()\n",
    "len(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a01ea981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arlo-hub-01',\n",
       " 'august-hub-01',\n",
       " 'august-hub-02',\n",
       " 'blink-cam-01',\n",
       " 'blink-cam-02',\n",
       " 'blink-cam-03',\n",
       " 'blink-hub-01',\n",
       " 'geeni-awarecam-1',\n",
       " 'geeni-awarecam-2',\n",
       " 'geeni-cam-03',\n",
       " 'geeni-doorbell-02',\n",
       " 'hue-hub-01',\n",
       " 'lockly-hub-01',\n",
       " 'merkury-cam-01',\n",
       " 'merkury-doorbell-01',\n",
       " 'nest-doorbell-01',\n",
       " 'ring-doorbell-03',\n",
       " 'schlage-lock-01',\n",
       " 'sifely-hub-01',\n",
       " 'simplisafe-d1',\n",
       " 'simplisafe-d2',\n",
       " 'smartthings-cam-01',\n",
       " 'smartthings-hub-01',\n",
       " 'ultraloq-hub-01']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a094b73a",
   "metadata": {},
   "source": [
    "### Hyperparameters of machine learning algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9e82cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_list={\n",
    "\"DT_r\":DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=22,\n",
    "                       max_features=1.0, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0, \n",
    "                       min_samples_leaf=1, min_samples_split=4,\n",
    "                       min_weight_fraction_leaf=0.0,\n",
    "                       random_state=None, splitter='best'),  \n",
    " \"Random Forest R\":RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "                       max_depth=27, max_features=1, max_leaf_nodes=None,\n",
    "                       min_impurity_decrease=0.0,\n",
    "                       min_samples_leaf=1, min_samples_split=10,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=69,\n",
    "                       n_jobs=None, oob_score=False, random_state=None,\n",
    "                       verbose=0, warm_start=False)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4d1596",
   "metadata": {},
   "source": [
    "### This part is the main part of the file. Cross-validates the respective datasets 10-time 10-fold and prints the results (general results, class-based results and confusion matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58437a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset         T   CV  ML alg  Acc   b_Acc Prec  Rec   F1    kap   tra-T    test-T  total   \n",
      "et/Threshold_0.075 0   1   DT_r    0.75  0.6   0.65  0.6   0.59  0.73  4.09     0.05    4.15    \n",
      "et/Threshold_0.075 0   2   DT_r    0.75  0.6   0.66  0.6   0.59  0.73  3.95     0.05    4.0     \n",
      "et/Threshold_0.075 0   3   DT_r    0.75  0.59  0.66  0.59  0.58  0.73  4.08     0.05    4.13    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m test_time\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m((time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39msecond)) )\n\u001b[1;32m     57\u001b[0m rc\u001b[38;5;241m=\u001b[39msklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mrecall_score(y_test, predict,average\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m pr\u001b[38;5;241m=\u001b[39msklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mprecision_score(y_test, predict,average\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m f_1\u001b[38;5;241m=\u001b[39msklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mf1_score(y_test, predict,average\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m\"\u001b[39m)        \n\u001b[1;32m     60\u001b[0m report \u001b[38;5;241m=\u001b[39m classification_report(y_test, predict, target_names\u001b[38;5;241m=\u001b[39mtarget_names,output_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2127\u001b[0m, in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1970\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m   1971\u001b[0m     {\n\u001b[1;32m   1972\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1997\u001b[0m ):\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the precision.\u001b[39;00m\n\u001b[1;32m   1999\u001b[0m \n\u001b[1;32m   2000\u001b[0m \u001b[38;5;124;03m    The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2125\u001b[0m \u001b[38;5;124;03m    array([0.5, 1. , 1. ])\u001b[39;00m\n\u001b[1;32m   2126\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2127\u001b[0m     p, _, _, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   2128\u001b[0m         y_true,\n\u001b[1;32m   2129\u001b[0m         y_pred,\n\u001b[1;32m   2130\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   2131\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[1;32m   2132\u001b[0m         average\u001b[38;5;241m=\u001b[39maverage,\n\u001b[1;32m   2133\u001b[0m         warn_for\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m,),\n\u001b[1;32m   2134\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   2135\u001b[0m         zero_division\u001b[38;5;241m=\u001b[39mzero_division,\n\u001b[1;32m   2136\u001b[0m     )\n\u001b[1;32m   2137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m p\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1725\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1724\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1725\u001b[0m MCM \u001b[38;5;241m=\u001b[39m multilabel_confusion_matrix(\n\u001b[1;32m   1726\u001b[0m     y_true,\n\u001b[1;32m   1727\u001b[0m     y_pred,\n\u001b[1;32m   1728\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1729\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   1730\u001b[0m     samplewise\u001b[38;5;241m=\u001b[39msamplewise,\n\u001b[1;32m   1731\u001b[0m )\n\u001b[1;32m   1732\u001b[0m tp_sum \u001b[38;5;241m=\u001b[39m MCM[:, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1733\u001b[0m pred_sum \u001b[38;5;241m=\u001b[39m tp_sum \u001b[38;5;241m+\u001b[39m MCM[:, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:184\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    186\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:533\u001b[0m, in \u001b[0;36mmultilabel_confusion_matrix\u001b[0;34m(y_true, y_pred, sample_weight, labels, samplewise)\u001b[0m\n\u001b[1;32m    531\u001b[0m le\u001b[38;5;241m.\u001b[39mfit(labels)\n\u001b[1;32m    532\u001b[0m y_true \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(y_true)\n\u001b[0;32m--> 533\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mtransform(y_pred)\n\u001b[1;32m    534\u001b[0m sorted_labels \u001b[38;5;241m=\u001b[39m le\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m# labels are now from 0 to len(labels) - 1 -> use bincount\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/preprocessing/_label.py:137\u001b[0m, in \u001b[0;36mLabelEncoder.transform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _encode(y, uniques\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/_encode.py:233\u001b[0m, in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my contains previously unseen labels: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(diff)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msearchsorted(uniques, values)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36msearchsorted\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1413\u001b[0m, in \u001b[0;36msearchsorted\u001b[0;34m(a, v, side, sorter)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_searchsorted_dispatcher)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearchsorted\u001b[39m(a, v, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, sorter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;124;03m    Find indices where elements should be inserted to maintain order.\u001b[39;00m\n\u001b[1;32m   1349\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1411\u001b[0m \n\u001b[1;32m   1412\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearchsorted\u001b[39m\u001b[38;5;124m'\u001b[39m, v, side\u001b[38;5;241m=\u001b[39mside, sorter\u001b[38;5;241m=\u001b[39msorter)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ths = open(\"dataset/Threshold_0.06_Accuracy.csv\", \"w\")\n",
    "ths.write(\"Dataset,T,CV,ML algorithm,Acc,b_Acc,Precision, Recall , F1-score, kappa ,tra-Time,test-Time,total-Time))\\n\")\n",
    "repetition=10\n",
    "\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import Normalizer\n",
    "print ('%-15s %-3s %-3s %-6s  %-5s %-5s %-5s %-5s %-5s %-5s %-8s %-8s%-8s'%\n",
    "           (\"Dataset\",\"T\",\"CV\",\"ML alg\",\"Acc\",\"b_Acc\",\"Prec\", \"Rec\" , \"F1\", \"kap\" ,\"tra-T\",\"test-T\",\"total\"))\n",
    "curr_file=[]\n",
    "curr_file.append(files_add[5])\n",
    "for loop in curr_file:\n",
    "    for ii in ml_list:\n",
    "        class_based_results=pd.DataFrame()#\"\" #pd.DataFrame(0, index=np.arange((len(target_names)+3)), columns=[\"f1-score\",\"precision\",\"recall\",\"support\"])\n",
    "        cm=pd.DataFrame()\n",
    "        for i in range(repetition):\n",
    "            rnd = random()\n",
    "            kfold = KFold(n_splits=10, shuffle=True, random_state=int(rnd*100))  \n",
    "            cv=0\n",
    "            df = pd.read_csv(loop)#,header=None )\n",
    "            del df[\"MAC\"] # if dataset has MAC colomn please uncomment this line\n",
    "            X =df[df.columns[0:-1]]\n",
    "            X=np.array(X)\n",
    "            df[df.columns[-1]] = df[df.columns[-1]].astype('category')\n",
    "            y=df[df.columns[-1]].cat.codes  \n",
    "            #scaler = Normalizer().fit(X)\n",
    "            #X = scaler.transform(X)\n",
    "            # summarize transformed data\n",
    "            dname=loop[7:-4]\n",
    "            X.shape\n",
    "            for train_index, test_index in kfold.split(X):\n",
    "                results_y=[]\n",
    "                X_train, X_test = X[train_index], X[test_index]\n",
    "                y_train, y_test = y[train_index], y[test_index]  \n",
    "                cv+=1\n",
    "                results_y.append(y_test)\n",
    "\n",
    "\n",
    "                precision=[]\n",
    "                recall=[]\n",
    "                f1=[]\n",
    "                accuracy=[]\n",
    "                train_time=[]\n",
    "                test_time=[]\n",
    "                total_time=[]\n",
    "                kappa=[]\n",
    "                accuracy_b=[]\n",
    "                    #machine learning algorithm is applied in this section\n",
    "                clf = ml_list[ii]#choose algorithm from ml_list dictionary\n",
    "                second=time.time()\n",
    "                clf.fit(X_train, y_train)\n",
    "                train_time.append(float((time.time()-second)) )\n",
    "                second=time.time()\n",
    "                predict =clf.predict(X_test)\n",
    "                test_time.append(float((time.time()-second)) )\n",
    "\n",
    "                rc=sklearn.metrics.recall_score(y_test, predict,average= \"macro\")\n",
    "                pr=sklearn.metrics.precision_score(y_test, predict,average= \"macro\")\n",
    "                f_1=sklearn.metrics.f1_score(y_test, predict,average= \"macro\")        \n",
    "                report = classification_report(y_test, predict, target_names=target_names,output_dict=True)\n",
    "                cr = pd.DataFrame(report).transpose()\n",
    "                if class_based_results.empty:\n",
    "                    class_based_results =cr\n",
    "                else:\n",
    "                    class_based_results = class_based_results.add(cr, fill_value=0)\n",
    "                precision.append(float(pr))\n",
    "                recall.append(float(rc))\n",
    "                f1.append(float(f_1))\n",
    "                accuracy_b.append(balanced_accuracy_score( y_test,predict))\n",
    "                accuracy.append(accuracy_score(y_test, predict))\n",
    "                #clf.score(X_test, y_test))\n",
    "                #print(balanced_accuracy_score( y_test,predict))\n",
    "                #t_time.append(float((time.time()-second)) )\n",
    "                kappa.append(round(float(sklearn.metrics.cohen_kappa_score(y_test, predict, \n",
    "                labels=None, weights=None, sample_weight=None)),15))\n",
    "                print ('%-15s %-3s %-3s %-6s  %-5s %-5s %-5s %-5s %-5s %-5s %-8s %-8s%-8s' % (dname,i,cv,ii[0:6],str(round(np.mean(accuracy),2)),str(round(np.mean(accuracy_b),2)),\n",
    "                    str(round(np.mean(precision),2)), str(round(np.mean(recall),2)),str(round(np.mean(f1),2)), \n",
    "                    str(round(np.mean(kappa),2)),str(round(np.mean(train_time),2)),str(round(np.mean(test_time),2)),str(round(np.mean(test_time)+np.mean(train_time),2))))\n",
    "                lines=(str(dname)+\",\"+str(i)+\",\"+str(cv)+\",\"+str(ii)+\",\"+str(round(np.mean(accuracy),15))+\",\"+str(round(np.mean(accuracy_b),15))+\",\"+str(round(np.mean(precision),15))+\",\"+ str(round(np.mean(recall),15))+\",\"+str(round(np.mean(f1),15))+\",\"+str(round(np.mean(kappa),15))+\",\"+str(round(np.mean(train_time),15))+\",\"+str(round(np.mean(test_time),15))+\",\"+str(round(np.mean(test_time)+np.mean(train_time),15))+\"\\n\")\n",
    "\n",
    "                ths.write (lines)\n",
    "\n",
    "                df_cm = pd.DataFrame(confusion_matrix(y_test, predict))\n",
    "                results_y.append(predict)\n",
    "                if cm.empty:\n",
    "                    cm =df_cm\n",
    "                else:\n",
    "                    cm = cm.add(df_cm, fill_value=0)\n",
    " \n",
    "        print(class_based_results/100) \n",
    "        cm=cm/100\n",
    "        graph_name=\"confusion matrix\" +str(ii)       \n",
    "        plt.figure(figsize = (20,14))\n",
    "        sns.heatmap(cm,xticklabels=target_names, yticklabels=target_names, annot=True)\n",
    "        plt.savefig(graph_name,bbox_inches='tight')#, dpi=400)\n",
    "        plt.show()\n",
    "        #print(cm)\n",
    "        print(\"\\n\\n\\n\") \n",
    "ths.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430c6504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
